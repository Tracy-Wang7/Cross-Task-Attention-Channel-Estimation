{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3832,"status":"ok","timestamp":1701106860678,"user":{"displayName":"tracy wang","userId":"14368895960430015677"},"user_tz":0},"id":"T85ZoH6JGKyn"},"outputs":[],"source":["import numpy as np\n","import random\n","from tensorflow.keras import *\n","from tensorflow.keras.layers import *\n","#from generations_comnet import *\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from keras import backend as backend\n","import os\n","import scipy.io as sio\n","import argparse\n","from scipy.interpolate import interp1d\n","\n"]},{"cell_type":"markdown","source":["# Completed code"],"metadata":{"id":"KBMO8JAYZhzh"}},{"cell_type":"markdown","source":["## load data and communication simulation"],"metadata":{"id":"A32pyZBDasQE"}},{"cell_type":"code","source":["### import channel matrix for training and testing\n","num_train = 500*2500 # 2500 PDP, each PDP 500 channel,\n","num_test = 10000 * 5 # 5 PDP, each PDP 10000 channel\n","\n","\n","K = 72#length of symbol after modulation\n","\n","\n","#channel_train = np.random.rand(num_train, K) + 1j*np.random.rand(num_train, K)\n","#channel_test = np.random.rand(num_test, K) + 1j*np.random.rand(num_test, K)\n","channel_train = np.loadtxt('path_for_channel_train.txt')\n","channel_test = np.loadtxt('path_for_channel_test.txt')\n","Pilot_file_name = 'file_path.txt'\n","\n","####################### Training configuration #######################\n","num_channel_per_PDP = 500\n","num_training_per_batch = 500\n","steps_per_epoch_train = 1\n","epochs_train = 1\n","saving_path_cross_attention = 'save_path_cross_attention.h5'\n","\n","\n","####################### Testing configuration #######################\n","num_testing_PDP = 5\n","num_testing_channel_per_PDP = 500\n","SNR_list = [5,10,15,20,25]\n","\n","####################### function for conventional wireless communication #######################\n","num_few_shots = 16 #### number of few-shot samples during new environment adaptation\n","feature_dims = 32 #### feature map dimension\n","CP = K\n","P = 18#num of pilots\n","allCarriers = np.arange(K)  # indices of all subcarriers position([0, 1, ... K-1])\n","mu = 2\n","payloadBits_per_OFDM = K * mu\n","bitses = np.random.binomial(n=1, p=0.5, size=(num_testing_channel_per_PDP*mu, payloadBits_per_OFDM)) ### save it in the first time to keep testing bits same\n","#bitses = np.loadtxt('path_for_testing_bits_72.txt',delimiter=',')\n","SNRdb = 25\n","if P < K:\n","    pilotCarriers = allCarriers[::K // P]  # Pilots is every (K/P)th carrier.\n","    #pilotCarriers[-1] = 71\n","    dataCarriers = np.delete(allCarriers, pilotCarriers)\n","\n","else:  # K = P\n","    pilotCarriers = allCarriers\n","    dataCarriers = []\n","\n","def interp(y):\n","\n","    x = np.arange(len(y))\n","    idx = np.nonzero(y)\n","    interp = interp1d(x[idx],y[idx])\n","\n","    return interp(x)\n","\n","def Modulation(bits):\n","    bit_r = bits.reshape((int(len(bits) / mu), mu))\n","    # This is just for QPSK modulation\n","    return np.sqrt(2)*(2 * bit_r[:, 0] - 1) + np.sqrt(2)*1j * (2 * bit_r[:, 1] - 1)\n","\n","def OFDM_symbol(Data, pilot_flag):\n","    symbol = np.zeros(K, dtype=complex)  # the overall K subcarriers\n","    #symbol = np.zeros(K)\n","    symbol[pilotCarriers] = pilotValue  # allocate the pilot subcarriers\n","    return symbol\n","\n","\n","def IDFT(OFDM_data):\n","    return np.fft.ifft(OFDM_data)\n","\n","\n","def addCP(OFDM_time):\n","    #cp = OFDM_time[-CP:]\n","    cp = OFDM_time[0:CP]             # take the last CP samples ...\n","    #return np.hstack([cp, OFDM_time])  # ... and add them to the beginning\n","    return np.concatenate((cp, OFDM_time))\n","\n","\n","def channel(signal, channelResponse, SNRdb):\n","    convolved = np.convolve(signal, channelResponse)\n","    signal_power = np.mean(abs(convolved**2))\n","    sigma2 = signal_power * 10**(-SNRdb / 10)\n","    noise = np.sqrt(sigma2 / 2) * (np.random.randn(*\n","                                                   convolved.shape) + 1j * np.random.randn(*convolved.shape))\n","    return convolved + noise\n","    #return convolved\n","\n","\n","def removeCP(signal):\n","    return signal[CP:(CP + K)]\n","\n","\n","def DFT(OFDM_RX):\n","    return np.fft.fft(OFDM_RX)\n","\n","\n","def ofdm_simulate(codeword, channelResponse, SNRdb):\n","    \"\"\"\n","    :param codeword: data to modulation\n","    \"\"\"\n","    # ----- Calculate h_ls using pilots   ---\n","    bits = np.random.binomial(n=1, p=0.5, size=(2*(K - P),))\n","    QAM = Modulation(bits)\n","    OFDM_data = np.zeros(K, dtype=complex)\n","    h_ls = np.zeros(K, dtype=complex)\n","    OFDM_data[pilotCarriers] = pilotValue#put pilot at position [0:64]\n","    OFDM_data[dataCarriers] = QAM\n","    OFDM_time = IDFT(OFDM_data)\n","    OFDM_withCP = addCP(OFDM_time)\n","    OFDM_TX = OFDM_withCP\n","    OFDM_RX = channel(OFDM_TX, channelResponse, SNRdb)\n","    OFDM_RX_noCP = removeCP(OFDM_RX)\n","    OFDM_RX_noCP = DFT(OFDM_RX_noCP)\n","    h_ls[pilotCarriers]=OFDM_RX_noCP[pilotCarriers]/pilotValue#LS estimation\n","    h_ls_concat = np.concatenate((np.real(h_ls), np.imag(h_ls)))\n","    h_ls_concat = h_ls_concat.reshape(2,K)\n","    h_ls_reshape = h_ls_concat.T\n","\n","\n","\n","\n","\n","    h_true = np.fft.fft(channelResponse)\n","    h_concat = np.concatenate((np.real(h_true), np.imag(h_true)))\n","    h_concat = h_concat.reshape(2,K)\n","    h_groundtruth = h_concat.T\n","\n","\n","    # ----- target inputs ---\n","    symbol = np.zeros(K, dtype=complex)\n","    codeword_qam = Modulation(codeword)#modualte 128 data bits data into 64 symbol\n","    symbol[np.arange(K)] = codeword_qam\n","    OFDM_data_codeword = symbol\n","    OFDM_time_codeword = np.fft.ifft(OFDM_data_codeword)\n","    OFDM_withCP_cordword = addCP(OFDM_time_codeword)\n","    OFDM_RX_codeword = channel(OFDM_withCP_cordword, channelResponse, SNRdb)\n","    OFDM_RX_noCP_codeword = removeCP(OFDM_RX_codeword)\n","    OFDM_RX_noCP_codeword = DFT(OFDM_RX_noCP_codeword)\n","    return (h_ls_reshape,\n","            np.concatenate((np.real(OFDM_RX_noCP_codeword), np.imag(OFDM_RX_noCP_codeword)))\n","            , h_groundtruth)\n","\n","\n","if os.path.isfile(Pilot_file_name):\n","    print('Load Training Pilots txt')\n","    # load file\n","    bits = np.loadtxt(Pilot_file_name, delimiter=',')\n","else:\n","    # write file\n","    bits = np.random.binomial(n=1, p=0.5, size=(P * mu, ))#randomly generate data via binomal distribution\n","    np.savetxt(Pilot_file_name, bits, delimiter=',')\n","\n","\n","pilotValue = Modulation(bits)#modulate data into pilots"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmRbtaoAZuM-","executionInfo":{"status":"ok","timestamp":1701108907140,"user_tz":0,"elapsed":3598,"user":{"displayName":"tracy wang","userId":"14368895960430015677"}},"outputId":"9e4aa53d-25ca-4569-dc76-c0c2239fc927"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Load Training Pilots txt\n"]}]},{"cell_type":"markdown","source":["## generate dataset for the meta-learner"],"metadata":{"id":"n0J31zx3idXF"}},{"cell_type":"code","source":["bits_pilot_few_shot = np.random.choice([0, 1], size=K*mu)\n","pilotValue_few_shot = Modulation(bits_pilot_few_shot)\n","pilotCarriers_few_shot = np.arange(K)\n","\n","\n","\n","def ofdm_simulate_hypernet_train(channelResponse, SNRdb):\n","    \"\"\"\n","    :param codeword: data to modulation\n","    \"\"\"\n","    # ----- Calculate h_ls using pilots   ---\n","    OFDM_data = np.zeros(K, dtype=complex)\n","    h_ls = np.zeros(K, dtype=complex)\n","\n","    OFDM_data[pilotCarriers_few_shot] = pilotValue_few_shot#put pilot at position [0:64]\n","    OFDM_time = IDFT(OFDM_data)\n","    OFDM_withCP = addCP(OFDM_time)\n","    OFDM_TX = OFDM_withCP\n","    OFDM_RX = channel(OFDM_TX, channelResponse, SNRdb)\n","    OFDM_RX_noCP = removeCP(OFDM_RX)\n","    OFDM_RX_noCP = DFT(OFDM_RX_noCP)\n","    #h_ls = OFDM_RX_noCP/pilotValue#LS estimation\n","    #h_true = np.fft.fft(channelResponse)\n","    h_ls[pilotCarriers_few_shot]=OFDM_RX_noCP[pilotCarriers_few_shot]/pilotValue_few_shot#LS estimation\n","    h_ls_concat = np.concatenate((np.real(h_ls), np.imag(h_ls)))\n","    h_ls_concat = h_ls_concat.reshape(2,K)\n","    h_ls_reshape = h_ls_concat.T\n","\n","\n","    h_true = np.fft.fft(channelResponse)\n","    h_concat = np.concatenate((np.real(h_true), np.imag(h_true)))\n","    h_concat = h_concat.reshape(2,K)\n","    h_groundtruth = h_concat.T\n","\n","    return h_ls_reshape, h_groundtruth\n","\n","\n","def hyper_set_generation():\n","    h_hyper_train_dataset = []\n","    h_hyper_train_label = []\n","    h_hyper_test_dataset = []\n","    h_hyper_test_label = []\n","\n","    for i in range(len(channel_train)):\n","      H = channel_train[i]\n","      h_ls,h_true = ofdm_simulate_hypernet_train(H, SNRdb)\n","      #h_ls_time_domain = np.fft.ifft(h_ls)\n","      h_hyper_train_dataset.append(h_ls)\n","      h_hyper_train_label.append(h_true)\n","\n","\n","    h_hyper_train_dataset = np.array(h_hyper_train_dataset)\n","    h_hyper_train_label = np.array(h_hyper_train_label)\n","\n","\n","    for i in range(len(channel_test)):\n","      H = channel_test[i]\n","      h_ls,h_true = ofdm_simulate_hypernet_train(H, SNRdb)\n","      #h_ls_time_domain = np.fft.ifft(h_ls)\n","      h_hyper_test_dataset.append(h_ls)\n","      h_hyper_test_label.append(h_true)\n","\n","    h_hyper_test_dataset = np.array(h_hyper_test_dataset)\n","    h_hyper_test_label = np.array(h_hyper_test_label)\n","    return h_hyper_train_dataset, h_hyper_train_label, h_hyper_test_dataset, h_hyper_test_label\n","\n","def hyper_set_generation_various_SNR():\n","    h_hyper_test_dataset_various_SNR = []\n","    SNR_list = [5,10,15,20,25]\n","    for i in range(5):\n","      SNRdb = SNR_list[i]\n","      h_hyper_test_dataset_copy = []\n","      for i in range(len(channel_test)):\n","        H = channel_test[i]\n","        h_ls,h_true = ofdm_simulate_hypernet_train(H, SNRdb)\n","        #h_ls_time_domain = np.fft.ifft(h_ls)\n","        h_hyper_test_dataset_copy.append(h_ls)\n","      h_hyper_test_dataset_various_SNR.append(np.array(h_hyper_test_dataset_copy))\n","\n","    h_hyper_test_dataset_various_SNR = np.array(h_hyper_test_dataset_various_SNR)\n","    return h_hyper_test_dataset_various_SNR\n","\n","h_hyper_train_dataset, h_hyper_train_label, h_hyper_test_dataset, h_hyper_test_label = hyper_set_generation()\n","h_hyper_test_dataset_various_SNR = hyper_set_generation_various_SNR()"],"metadata":{"id":"hVaaAfF0iiy7","executionInfo":{"status":"ok","timestamp":1701109085203,"user_tz":0,"elapsed":172064,"user":{"displayName":"tracy wang","userId":"14368895960430015677"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## pre-train feature extraction network"],"metadata":{"id":"z_ZvjqE6a0DI"}},{"cell_type":"code","source":["def feature_extractor(feature_dims):\n","  input_LS = Input(shape=(int(payloadBits_per_OFDM/2),2),name = 'input')  # Channel LS estimation\n","\n","  x_1 = Conv1D(64*5, 8, padding = 'same', activation = 'linear',name = 'extractor_1')(input_LS)\n","  x_2 = Conv1D(64*5, 8, padding = 'same', activation = 'linear',name = 'extractor_2')(x_1)\n","  x_3 = Conv1D(feature_dims, 3, padding = 'same', activation = 'linear',name = 'extractor_3')(x_2)\n","\n","  final_output = Conv1D(2, 2,padding = 'same',activation = 'linear',name = 'channel6')(x_3)\n","\n","  model = Model(inputs=input_LS, outputs=final_output)\n","  return model\n","\n","\n","def pre_trained_feature_extractor(feature_dims):\n","  input_LS = Input(shape=(int(payloadBits_per_OFDM/2),2),name = 'input')  # Channel LS estimation\n","\n","  x_1 = Conv1D(64*5, 8, padding = 'same', activation = 'linear',name = 'extractor_1')(input_LS)\n","  x_2 = Conv1D(64*5, 8, padding = 'same', activation = 'linear',name = 'extractor_2')(x_1)\n","  x_3 = Conv1D(feature_dims, 3, padding = 'same', activation = 'linear',name = 'extractor_3')(x_2)\n","\n","  model = Model(inputs=input_LS, outputs=x_3)\n","  return model\n","\n","def generate_hyper_samples(class_idx, num_combined, h_hyper_train_dataset, h_hyper_train_label, SNR_ratio):\n","  idx = random.sample(range(class_idx*num_channel_per_PDP,(class_idx+1)*num_channel_per_PDP), num_combined)\n","  return h_hyper_train_dataset[idx],h_hyper_train_label[idx]\n","\n","def training_gen_hyper(bs, num_combined, h_hyper_train_dataset, h_hyper_train_label, SNRdb = 20):\n","    while True:\n","        index = np.random.choice(np.arange(len(channel_train)), size=bs)#choose bs daa from trainsets\n","        H_total = channel_train[index]\n","        input_hls = []\n","        input_h_labels = []\n","\n","        #for H in H_total:\n","        for i in index:\n","            #H = channel_trainingset[index]\n","            H =channel_train[i]\n","            class_idx = int(i/num_channel_per_PDP)\n","            vec_input, vec_true= generate_hyper_samples(class_idx,num_combined, h_hyper_train_dataset, h_hyper_train_label, SNRdb)\n","            input_hls.append(vec_input)\n","            input_h_labels.append(vec_true)\n","\n","\n","        yield ({'input':np.asarray(input_hls)}, {'channel6':np.asarray(input_h_labels)})\n","        #return np.asarray(input_vec)\n","\n","def validation_gen_hyper(bs, num_combined, h_hyper_train_dataset, h_hyper_train_label, SNRdb = 20):\n","    while True:\n","        index = np.random.choice(np.arange(len(channel_train)), size=bs)\n","        H_total = channel_train[index]\n","\n","        input_hls = []\n","        input_h_labels = []\n","        for i in index:\n","            H=channel_train[i]\n","            class_idx = int(i/num_channel_per_PDP)\n","            vec_input, vec_true= generate_hyper_samples(class_idx,num_combined,h_hyper_train_dataset, h_hyper_train_label, SNRdb)\n","            input_hls.append(vec_input)\n","            input_h_labels.append(vec_true)\n","\n","        # sio.savemat('y_real+imag_{}.mat'.format(str(SNRdb)),{'y_SNR_{}'.format(str(SNRdb)):input_data})\n","        # sio.savemat('init_bits_{}.mat'.format(str(SNRdb)), {'bit_SNR_{}'.format(str(SNRdb)):all_bits})\n","        # sio.savemat('h_ls_real+imag_{}.mat'.format(str(SNRdb)), {'h_SNR_{}'.format(str(SNRdb)): input_hls})\n","\n","        yield ({'input':np.asarray(input_hls)}, {'channel6':np.asarray(input_h_labels)})\n","\n","def train_for_feature_extraction(num_few_shots, feature_dims, h_hyper_train_dataset, h_hyper_train_label):\n","  num_combined = num_few_shots\n","  model_extractor = feature_extractor(feature_dims)\n","\n","  model_extractor.compile(optimizer='adam', loss='mse',  metrics=[tf.keras.metrics.MeanSquaredError()])\n","  checkpoint = callbacks.ModelCheckpoint('dual.h5',\n","                                          verbose=0, save_best_only=True, mode='min', save_weights_only=True)\n","  model_extractor.fit_generator(\n","      training_gen_hyper(num_training_per_batch,num_combined, h_hyper_train_dataset, h_hyper_train_label, SNRdb),\n","      steps_per_epoch=steps_per_epoch_train,\n","      epochs=epochs_train,\n","      validation_data=validation_gen_hyper(num_training_per_batch,num_combined,h_hyper_train_dataset, h_hyper_train_label, SNRdb),\n","      validation_steps=1,\n","      callbacks=[checkpoint],\n","      verbose=2)\n","  return model_extractor\n","\n","\n","\n","\n","\n","def feature_map_extraction(model, feature_dims, h_hyper_train_dataset):\n","  feature_extractor_pre_trained = pre_trained_feature_extractor(feature_dims)\n","\n","  feature_extractor_pre_trained.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.MeanSquaredError()])\n","\n","  layername = ['extractor_1','extractor_2','extractor_3']\n","  for i in range(len(layername)):\n","    for layer in feature_extractor_pre_trained.layers:\n","      if layer.name == layername[i]:\n","          layer.trainable = False\n","\n","  for i in range(len(layername)):\n","    for layer in feature_extractor_pre_trained.layers:\n","      if layer.name == layername[i]:\n","        for layerss in model.layers:\n","          if layerss.name == layername[i]:\n","            layer.set_weights(layerss.get_weights())\n","\n","\n","  h_hyper_feature_map = []\n","  for i in range(int(len(h_hyper_train_dataset)/1000)):\n","    input_data = h_hyper_train_dataset[int(i*1000):int((i+1)*1000)]\n","    input_feature_map = feature_extractor_pre_trained.predict(input_data, verbose=0)\n","    h_hyper_feature_map.append(input_feature_map)\n","\n","  h_hyper_feature_map = np.array(h_hyper_feature_map)\n","  h_hyper_feature_map = h_hyper_feature_map.reshape(len(h_hyper_train_dataset),K,feature_dims)\n","  return h_hyper_feature_map\n","\n","\n","def feature_map_extraction_varying_SNR(model, feature_dims, h_hyper_test_dataset_various_SNR):\n","  feature_extractor_pre_trained = pre_trained_feature_extractor(feature_dims)\n","\n","  feature_extractor_pre_trained.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.MeanSquaredError()])\n","\n","  layername = ['extractor_1','extractor_2','extractor_3']\n","  for i in range(len(layername)):\n","    for layer in feature_extractor_pre_trained.layers:\n","      if layer.name == layername[i]:\n","          layer.trainable = False\n","\n","  for i in range(len(layername)):\n","    for layer in feature_extractor_pre_trained.layers:\n","      if layer.name == layername[i]:\n","        for layerss in model.layers:\n","          if layerss.name == layername[i]:\n","            layer.set_weights(layerss.get_weights())\n","\n","\n","  SNR_list = [5,10,15,20,25]\n","  h_hyper_testing_feature_map_various_SNR = []\n","  for z in range(5):\n","    h_hyper_testing_feature_map = []\n","    for i in range(int(len(h_hyper_test_dataset_various_SNR[0])/1000)):\n","      input_data = h_hyper_test_dataset_various_SNR[z,int(i*1000):int((i+1)*1000)]\n","      input_feature_map = feature_extractor_pre_trained.predict(input_data, verbose=0)\n","      h_hyper_testing_feature_map.append(input_feature_map)\n","\n","    h_hyper_testing_feature_map = np.array(h_hyper_testing_feature_map)\n","    h_hyper_testing_feature_map = h_hyper_testing_feature_map.reshape(50000,72,32)\n","    h_hyper_testing_feature_map_various_SNR.append(h_hyper_testing_feature_map)\n","\n","  h_hyper_testing_feature_map_various_SNR = np.array(h_hyper_testing_feature_map_various_SNR)\n","  return h_hyper_testing_feature_map_various_SNR\n","\n","\n","\n","feature_extraction = train_for_feature_extraction(num_few_shots, feature_dims, h_hyper_train_dataset, h_hyper_train_label)\n","h_hyper_feature_map = feature_map_extraction(feature_extraction, feature_dims, h_hyper_train_dataset)\n","h_hyper_testing_feature_map_various_SNR = feature_map_extraction_varying_SNR(feature_extraction, feature_dims, h_hyper_test_dataset_various_SNR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWd_BqiUXZvB","outputId":"04a73180-330a-4f33-b0ad-9457f640458b"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-11-81ee5601d85a>:75: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model_extractor.fit_generator(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["1/1 - 23s - loss: 24.4415 - mean_squared_error: 24.4415 - val_loss: 1.8483 - val_mean_squared_error: 1.8483 - 23s/epoch - 23s/step\n"]}]},{"cell_type":"markdown","source":["## cross_task_attention"],"metadata":{"id":"wWzhM1sSq6eH"}},{"cell_type":"code","source":["def generate_few_shot_samples(class_idx, num_few_shots, h_hyper_train_dataset, h_hyper_feature_map):\n","  idx = random.sample(range(class_idx*num_channel_per_PDP,(class_idx+1)*num_channel_per_PDP), num_few_shots)\n","  return h_hyper_train_dataset[idx], h_hyper_feature_map[idx]\n","\n","def training_gen(bs, num_few_shots, h_hyper_train_dataset, h_hyper_feature_map, train_size, SNRdb = 20):\n","    while True:\n","        index = np.random.choice(np.arange(train_size), size=bs)#choose bs daa from trainsets\n","        H_total = channel_train[index]\n","        input_hls = []\n","        input_h_labels = []\n","        input_vec = []\n","        input_vec_part_feature_map = []\n","        input_h_ls_feature_map = []\n","        for i in index:\n","            H =channel_train[i]\n","            class_idx = int(i/num_channel_per_PDP)\n","            vec_part, vec_part_feature_map = generate_few_shot_samples(class_idx, num_few_shots, h_hyper_train_dataset, h_hyper_feature_map)\n","            input_vec_part_feature_map.append(vec_part_feature_map)\n","\n","            input_vec.append(vec_part)\n","\n","            s_bits = np.random.binomial(n=1, p=0.5, size=(payloadBits_per_OFDM,))#randomly generate s_bits with length 128 bits\n","            h_ls,signal_output, h_true = ofdm_simulate(s_bits, H, SNRdb)\n","            input_hls.append(h_ls)#add h_ls to input_1\n","            input_h_labels.append(h_true)\n","\n","        yield ({'input_1':np.asarray(input_hls),'input_2':np.asarray(input_vec),'input_3':np.asarray(input_vec_part_feature_map)}, {'channel6':np.asarray(input_h_labels)})\n","\n","\n","def validation_gen(bs, num_few_shots, h_hyper_train_dataset, h_hyper_feature_map, train_size, SNRdb = 20):\n","    while True:\n","        index = np.random.choice(np.arange(train_size), size=bs)\n","        H_total = channel_train[index]\n","        input_hls = []\n","        input_h_labels = []\n","        input_vec = []\n","        input_vec_part_feature_map = []\n","        input_h_ls_feature_map = []\n","        for i in index:\n","            H =channel_train[i]\n","            class_idx = int(i/num_channel_per_PDP)\n","            vec_part,vec_part_feature_map = generate_few_shot_samples(class_idx, num_few_shots, h_hyper_train_dataset, h_hyper_feature_map)\n","            input_vec_part_feature_map.append(vec_part_feature_map)\n","\n","            input_vec.append(vec_part)\n","\n","            s_bits = np.random.binomial(n=1, p=0.5, size=(payloadBits_per_OFDM,))#randomly generate s_bits with length 128 bits\n","            h_ls,signal_output, h_true = ofdm_simulate(s_bits, H, SNRdb)\n","\n","            input_hls.append(h_ls)#add h_ls to input_1\n","            input_h_labels.append(h_true)\n","\n","        yield ({'input_1':np.asarray(input_hls),'input_2':np.asarray(input_vec),'input_3':np.asarray(input_vec_part_feature_map)}, {'channel6':np.asarray(input_h_labels)})\n","\n","def meta_learning(num_few_shots, feature_dims):\n","  input_GAP = Input(shape=(num_few_shots,1,K), name = 'input')\n","  RP_att = Conv1D(16,1,padding = \"same\", activation = 'relu',name = 'meta_leaner_1_1')(input_GAP)\n","  RP_att = Conv1D(K,1,padding = \"same\", activation = 'linear',name = 'meta_leaner_1_2')(RP_att)\n","\n","  model = Model(inputs=input_GAP, outputs=RP_att)\n","  return model\n","\n","def model_cross_attention_CNN(net_meta_learner, num_few_shots, feature_dims):\n","  input_LS = Input(shape=(int(payloadBits_per_OFDM/2),2),name = 'input_1')  # Channel LS estimation\n","  input_vec = Input(shape=(num_few_shots,K, 2,),name = 'input_2')\n","  input_vec_feature_map = Input(shape=(num_few_shots,K, feature_dims,),name = 'input_3')\n","  #input_LS_feature_map = Input(shape=(1,K, feature_dims,),name = 'input_4')\n","  x_1 = Conv1D(64*5, 8, padding = 'same', activation = 'linear',name = 'extractor_1')(input_LS)\n","  x_2 = Conv1D(64*5, 8, padding = 'same', activation = 'linear',name = 'extractor_2')(x_1)\n","  input_LS_feature_map = Conv1D(feature_dims, 3, padding = 'same', activation = 'linear',name = 'extractor_3')(x_2)\n","\n","  vec_feature_map_reshape = tf.reshape(input_vec_feature_map,[-1, input_vec_feature_map.shape[1]*input_vec_feature_map.shape[2],input_vec_feature_map.shape[3]])\n","  vec_feature_map_normalized = tf.linalg.normalize(vec_feature_map_reshape,axis = 2)[0]\n","  #vec_feature_map_normalized_reshape = tf.reshape(vec_feature_map_normalized,[-1,input_vec_feature_map.shape[1],input_vec_feature_map.shape[2],input_vec_feature_map.shape[3]])\n","  #LS_feature_map_reshape = tf.reshape(input_LS_feature_map,[-1, input_vec_feature_map.shape[2],input_vec_feature_map.shape[3]])\n","  LS_feature_map_reshape = input_LS_feature_map\n","  LS_feature_map_normalized = tf.linalg.normalize(LS_feature_map_reshape,axis = 2)[0]\n","  LS1_T = tf.transpose(LS_feature_map_normalized,perm = [0,2,1])\n","  R_combined = tf.matmul(vec_feature_map_normalized,LS1_T)\n","  R_P = tf.reshape(R_combined,[-1,num_few_shots, K,R_combined.shape[2]])\n","  R_Q = tf.transpose(R_P,perm = [0,1,3,2])\n","  RP_GAP = tf.reduce_mean(R_P, axis = 2, keepdims=True)\n","  RP_att = net_meta_learner(RP_GAP)\n","  RP_att = tf.transpose(RP_att,perm = [0,1,3,2])\n","  RP_multiply = tf.matmul(R_P,  RP_att)\n","  RP_attention = tf.nn.softmax(RP_multiply)+1.0\n","  weighted_vec_feature_map = input_vec_feature_map * RP_attention\n","\n","  RQ_GAP = tf.reduce_mean(R_Q, axis = 2, keepdims=True)\n","  RQ_att = net_meta_learner(RQ_GAP)\n","  RQ_att = tf.transpose(RQ_att,perm = [0,1,3,2])\n","  RQ_multiply = tf.matmul(R_Q,  RQ_att)\n","  RQ_attention = tf.nn.softmax(RQ_multiply)+1.0\n","  LS_feature_map_reshape = tf.reshape(LS_feature_map_reshape,[-1,1,LS_feature_map_reshape.shape[1],LS_feature_map_reshape.shape[2]])\n","  LS_feature_map_reshape = tf.tile(LS_feature_map_reshape,[1,num_few_shots,1,1])\n","  weighted_LS_feature_map = LS_feature_map_reshape * RQ_attention\n","\n","  feature_map = tf.concat([weighted_vec_feature_map,weighted_LS_feature_map],2)\n","  CNN_input_feature = tf.reshape(feature_map,[-1,num_few_shots*2,K,feature_dims])\n","\n","\n","\n","\n","\n","  x1 = Conv2D(64*3, (2,1), strides = (2,1), activation = 'relu',name = 'conv1')(CNN_input_feature)\n","  #x1p = AveragePoolin2g2D(pool_size=(5, 1),strides=(5, 1), padding='valid')(x1)\n","  x2 = Conv2D(64*3, 5, padding = \"same\", activation = 'relu',name = 'conv2')(x1)\n","  #x2p = AveragePooling2D(pool_size=(2, 1),strides=(2, 1), padding='valid')(x2)\n","  x3 = Conv2D(64*3, 5, padding = \"same\", activation = 'relu',name = 'conv3')(x2)\n","  #x3p = AveragePooling2D(pool_size=(2, 1),strides=(2, 1), padding='valid')(x3)\n","  x3 = x1+x3\n","  x4 = Conv2D(64, (2,1), strides = (2,1), activation = 'relu',name = 'conv4')(x3)\n","\n","  x5 = Conv2D(64, 5, padding = \"same\", activation = 'relu',name = 'conv5')(x4)\n","\n","  x6 = Conv2D(64, 5, padding = \"same\", activation = 'relu',name = 'conv6')(x5)\n","  x6 = x6+x4\n","\n","  x7 = Conv2D(8, 3, padding = \"same\", activation = 'linear',name = 'conv7')(x6)\n","  x8 = tf.reduce_mean(x7, axis = 1, keepdims=False)\n","\n","\n","\n","\n","\n","\n","  final_output_1 = Conv1D(2, 2,padding = 'same',activation = 'linear',name = 'channel6')(x8)\n","  model = Model(inputs=[input_LS, input_vec,input_vec_feature_map], outputs=final_output_1)\n","  return model\n","\n","\n","def model_cross_Task_CNN(net_meta_learner, num_few_shots, feature_dims):\n","  input_LS = Input(shape=(int(payloadBits_per_OFDM/2),2),name = 'input_1')  # Channel LS estimation\n","  input_vec = Input(shape=(num_few_shots,K, 2,),name = 'input_2')\n","  input_vec_feature_map = Input(shape=(num_few_shots,K, feature_dims,),name = 'input_3')\n","\n","\n","\n","\n","\n","\n","\n","  ################ Task Attntion ################\n","  x1 = Conv2D(64, 8, padding = \"same\", activation = 'relu',name = 'conv11')(input_vec)\n","  x2 = Conv2D(32, 5, padding = \"same\", activation = 'relu',name = 'conv22')(x1)\n","  x3 = Conv2D(16, 5, padding = \"same\", activation = 'relu',name = 'conv33')(x2)\n","  x4 = Conv2D(4, 2, padding = \"same\", activation = 'relu',name = 'conv44')(x3)\n","  x5 = Flatten()(x4)\n","  x5 = Dense(128,activation = 'relu', use_bias=False,name = 'dense128')(x5)\n","\n","  see1 = Dense(64*5, activation=\"sigmoid\", use_bias=False,name = 'see1')(x5)\n","\n","  see2 = Dense(64*5, activation=\"sigmoid\", use_bias=False,name = 'see2')(x5)\n","\n","  see3 = Dense(64*5, activation=\"sigmoid\", use_bias=False,name = 'see3')(x5)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","  ################ Cross Attntion ################\n","  x_1 = Conv1D(64*5, 8, padding = 'same', activation = 'linear',name = 'extractor_1')(input_LS)\n","  x_2 = Conv1D(64*5, 8, padding = 'same', activation = 'linear',name = 'extractor_2')(x_1)\n","  input_LS_feature_map = Conv1D(feature_dims, 3, padding = 'same', activation = 'linear',name = 'extractor_3')(x_2)\n","\n","  vec_feature_map_reshape = tf.reshape(input_vec_feature_map,[-1, input_vec_feature_map.shape[1]*input_vec_feature_map.shape[2],input_vec_feature_map.shape[3]])\n","  vec_feature_map_normalized = tf.linalg.normalize(vec_feature_map_reshape,axis = 2)[0]\n","  LS_feature_map_reshape = input_LS_feature_map\n","  LS_feature_map_normalized = tf.linalg.normalize(LS_feature_map_reshape,axis = 2)[0]\n","  LS1_T = tf.transpose(LS_feature_map_normalized,perm = [0,2,1])\n","  R_combined = tf.matmul(vec_feature_map_normalized,LS1_T)\n","  R_P = tf.reshape(R_combined,[-1,num_few_shots, K,R_combined.shape[2]])\n","  R_Q = tf.transpose(R_P,perm = [0,1,3,2])\n","  RP_GAP = tf.reduce_mean(R_P, axis = 2, keepdims=True)\n","  RP_att = net_meta_learner(RP_GAP)\n","  RP_att = tf.transpose(RP_att,perm = [0,1,3,2])\n","  RP_multiply = tf.matmul(R_P,  RP_att)\n","  RP_attention = tf.nn.softmax(RP_multiply)+1.0\n","  weighted_vec_feature_map = input_vec_feature_map * RP_attention\n","\n","  RQ_GAP = tf.reduce_mean(R_Q, axis = 2, keepdims=True)\n","  RQ_att = net_meta_learner(RQ_GAP)\n","  RQ_att = tf.transpose(RQ_att,perm = [0,1,3,2])\n","  RQ_multiply = tf.matmul(R_Q,  RQ_att)\n","  RQ_attention = tf.nn.softmax(RQ_multiply)+1.0\n","  LS_feature_map_reshape = tf.reshape(LS_feature_map_reshape,[-1,1,LS_feature_map_reshape.shape[1],LS_feature_map_reshape.shape[2]])\n","  LS_feature_map_reshape = tf.tile(LS_feature_map_reshape,[1,num_few_shots,1,1])\n","  weighted_LS_feature_map = LS_feature_map_reshape * RQ_attention\n","\n","  feature_map = tf.concat([weighted_vec_feature_map,weighted_LS_feature_map],2)\n","  CNN_input_feature = tf.reshape(feature_map,[-1,num_few_shots*2,K,feature_dims])\n","\n","\n","\n","\n","\n","  ################ Main Network ################\n","  x1 = Conv2D(64*3, (2,1), strides = (2,1), activation = 'relu',name = 'conv1')(CNN_input_feature)\n","  x2 = Conv2D(64*3, 5, padding = \"same\", activation = 'relu',name = 'conv2')(x1)\n","  x3 = Conv2D(64*3, 5, padding = \"same\", activation = 'relu',name = 'conv3')(x2)\n","  x3 = x1+x3\n","  x4 = Conv2D(64, (2,1), strides = (2,1), activation = 'relu',name = 'conv4')(x3)\n","  x5 = Conv2D(64, 5, padding = \"same\", activation = 'relu',name = 'conv5')(x4)\n","  x6 = Conv2D(64, 5, padding = \"same\", activation = 'relu',name = 'conv6')(x5)\n","  x6 = x6+x4\n","  x7 = Conv2D(8, 3, padding = \"same\", activation = 'linear',name = 'conv7')(x6)\n","  x8 = tf.reduce_mean(x7, axis = 1, keepdims=False)\n","  final_output_1 = Conv1D(2, 2,padding = 'same',activation = 'linear',name = 'channel6_1')(x8)\n","  x_1 = Conv1D(64*5, 8, padding = 'same', activation = 'linear',name = 'channel1')(final_output_1)\n","  sec = see1\n","  sec = tf.reshape(sec, [-1,1,64*5])\n","  x_1 = x_1*sec\n","  x = Conv1D(64*5, 8, padding = 'same', activation = 'linear', name = 'channel2')(x_1)\n","  sec = see2\n","  sec = tf.reshape(sec, [-1,1,64*5])\n","  x = x*sec\n","  x = x+x_1\n","  decoder_feature = Conv1D(64*5, 3, padding = 'same', activation = 'linear',name = 'channel3')(x)\n","  sec = see3\n","  sec = tf.reshape(sec, [-1,1,64*5])\n","  decoder_feature = decoder_feature*sec\n","  final_output = Conv1D(2, 2,padding = 'same',activation = 'linear',name = 'channel6')(decoder_feature)\n","  model = Model(inputs=[input_LS, input_vec,input_vec_feature_map], outputs=final_output)\n","  return model"],"metadata":{"id":"Zm3PQJGKrUoO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_experiment(model, num_few_shots, feature_dims, h_hyper_train_dataset, h_hyper_feature_map):\n","  net1 = meta_learning(num_few_shots, feature_dims)\n","  model_cross = model_cross_attention_CNN(net1, num_few_shots, feature_dims)\n","  model_cross.compile(optimizer='adam', loss='mse',  metrics=[tf.keras.metrics.MeanSquaredError()])\n","  checkpoint = callbacks.ModelCheckpoint('dual.h5',\n","                                          verbose=0, save_best_only=True, mode='min', save_weights_only=True)\n","\n","\n","\n","\n","  layername = ['extractor_1','extractor_2','extractor_3']\n","  for i in range(len(layername)):\n","    for layer in model_cross.layers:\n","      if layer.name == layername[i]:\n","          layer.trainable = False\n","\n","  for i in range(len(layername)):\n","    for layer in model_cross.layers:\n","      if layer.name == layername[i]:\n","        for layerss in model.layers:\n","          if layerss.name == layername[i]:\n","            layer.set_weights(layerss.get_weights())\n","\n","\n","\n","\n","  model_cross.fit_generator(\n","      training_gen(num_training_per_batch,num_few_shots,h_hyper_train_dataset, h_hyper_feature_map, len(h_hyper_train_dataset), SNRdb),\n","      steps_per_epoch=steps_per_epoch_train,\n","      epochs=epochs_train,\n","      validation_data=validation_gen(num_training_per_batch, num_few_shots,h_hyper_train_dataset, h_hyper_feature_map, len(h_hyper_train_dataset), SNRdb),\n","      validation_steps=1,\n","      callbacks=[checkpoint],\n","      verbose=2)\n","\n","  model_cross.save(saving_path_cross_attention)\n","\n","\n","  ############################### train task attention ###############################\n","  net_copy = meta_learning(num_few_shots, feature_dims)\n","  model_cross_copy = model_cross_attention_CNN(net_copy, num_few_shots, feature_dims)\n","  model_cross_copy.compile(optimizer='adam', loss='mse',  metrics=[tf.keras.metrics.MeanSquaredError()])\n","  model_cross_copy = tf.keras.saving.load_model(saving_path_cross_attention)\n","\n","  net1 = net_copy\n","  model_cross_Task = model_cross_Task_CNN(net1, num_few_shots, feature_dims)\n","  model_cross_Task.compile(optimizer='adam', loss='mse',  metrics=[tf.keras.metrics.MeanSquaredError()])\n","  checkpoint = callbacks.ModelCheckpoint('dual.h5',\n","                                          verbose=0, save_best_only=True, mode='min', save_weights_only=True)\n","  layername = ['meta_leaner_1_1','meta_leaner_1_2']\n","  for i in range(len(layername)):\n","    for layer in net1.layers:\n","      if layer.name == layername[i]:\n","          layer.trainable = False\n","  layername = ['extractor_1','extractor_2','extractor_3','conv1','conv2','conv3','conv4','conv5','conv6','conv7','channel6_1']\n","  for i in range(len(layername)):\n","    for layer in model_cross_Task.layers:\n","      if layer.name == layername[i]:\n","          layer.trainable = False\n","\n","  for i in range(len(layername)):\n","    for layer in model_cross_Task.layers:\n","      if layer.name == layername[i]:\n","        for layerss in model_cross_copy.layers:\n","          if layerss.name == layername[i]:\n","            layer.set_weights(layerss.get_weights())\n","\n","\n","\n","\n","  model_cross_Task.fit_generator(\n","      training_gen(num_training_per_batch,num_few_shots,h_hyper_train_dataset, h_hyper_feature_map, len(h_hyper_train_dataset),25),\n","      steps_per_epoch=steps_per_epoch_train,\n","      epochs=epochs_train,\n","      validation_data=validation_gen(num_training_per_batch, num_few_shots,h_hyper_train_dataset, h_hyper_feature_map, len(h_hyper_train_dataset), 25),\n","      validation_steps=1,\n","      callbacks=[checkpoint],\n","      verbose=2)\n","\n","  return model_cross_Task\n","\n","def test_prediction(model,num_few_shots, h_hyper_test_dataset_various_SNR, h_hyper_testing_feature_map_various_SNR, SNR_list):\n","\n","  for j in range(num_testing_PDP):\n","    SNR_record = []\n","    for z in range(len(SNR_list)):\n","      acc = 0\n","      for i in range(num_testing_channel_per_PDP):\n","        input_zero = np.zeros(shape=(int(2*num_few_shots),K,2))\n","        H = channel_test[int(j*10000+i+num_few_shots)]\n","        SNRdb = SNR_list[z]\n","        h_ls,signal_output, h_true = ofdm_simulate(bitses[i], H, SNRdb)\n","        h_ls_test = h_ls.reshape(1,h_ls.shape[0],h_ls.shape[1])\n","\n","        vec_few_shot = h_hyper_test_dataset_various_SNR[z,int(j*10000):int(j*10000+num_few_shots)] # +10000 for D1_4\n","        vec_few_shot = vec_few_shot.reshape(1,vec_few_shot.shape[0],vec_few_shot.shape[1],vec_few_shot.shape[2])\n","\n","        vec_feature_map = h_hyper_testing_feature_map_various_SNR[z,int(j*10000):int(j*10000+num_few_shots)] # +10000 for D1_4\n","        vec_feature_map = vec_feature_map.reshape(1,vec_feature_map.shape[0],vec_feature_map.shape[1],vec_feature_map.shape[2])\n","\n","\n","        h_pred = model.predict([h_ls_test,vec_few_shot,vec_feature_map], verbose=0)\n","\n","        H_pred = h_pred[:,:,0] +1j * h_pred[:,:,1]\n","        #h_pre = np.fft.ifft(H_pred)\n","        h_pre = H_pred\n","        h_pred_concat = np.concatenate((np.real(h_pre[0]),np.imag(h_pre[0])))\n","        H_freq = np.fft.fft(H)\n","        H_concat = np.concatenate((np.real(H_freq),np.imag(H_freq)))\n","        mse = ((h_pred_concat - H_concat)**2).mean()\n","        acc = acc+mse\n","      acc_mean = acc/num_testing_channel_per_PDP\n","      SNR_record.append(acc_mean)\n","    print(SNR_record)"],"metadata":{"id":"yzg-LUit92JW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_cross_Task = run_experiment(feature_extraction, num_few_shots, feature_dims, h_hyper_train_dataset, h_hyper_feature_map)\n","test_prediction(model_cross_Task, num_few_shots, h_hyper_test_dataset_various_SNR, h_hyper_testing_feature_map_various_SNR, SNR_list)"],"metadata":{"id":"vKyM0LaD6Gqq"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["ptlo2UJMwcIt","jaCz4eIdC0A4","gUxCE94idVHV","UljT0_Q0lc2X","qoPYK4nHvaNd"],"machine_shape":"hm","provenance":[{"file_id":"106za0dyw7UvH4z4gOZOfRE57ycl4UYRd","timestamp":1701106769110}],"authorship_tag":"ABX9TyPIqSsZEhlcevLadYpcGVPK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}